package com.ez.spark

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext

object q2 {
  	def main (args: Array[String]) {
//   val conf = new SparkConf().setAppName("duration_count").setMaster("local")
//   val sc = new SparkContext(conf)
//   val abcnews = sc.textFile("src/main/resources/abcnews.csv")
//   val positivewords = sc.textFile("src/main/resources/positives.txt")
//   val negativewords = sc.textFile("src/main/resources/negatives.txt")
//   val news = abcnews.map(f => f.split(",")(1))
//   val newstuples = news.map(f => (f,f))
//   val flatnews = newstuples.flatMapValues(f => f.split(" "))
//   val replaced_positives = flatnews.map(tuple =>  )
//   flatnews.foreach(println)
 }
}